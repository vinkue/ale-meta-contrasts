{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "402bf5f9-2323-47d7-bf7d-5aed88836679",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986501c2-18f3-4e00-9b44-51bc479693f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import nibabel as nib\n",
    "from nilearn import plotting\n",
    "from nilearn.image import math_img\n",
    "from matplotlib.colors import ListedColormap\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from neuromaps.datasets import fetch_fslr\n",
    "from neuromaps.transforms import mni152_to_fslr\n",
    "from surfplot import Plot\n",
    "from surfplot.utils import threshold\n",
    "\n",
    "from similarity import calculate_voxel_similarity\n",
    "from matplotlib_venn import venn2\n",
    "\n",
    "gm_mask = os.path.abspath('../pyALE/utils/mask/Grey10.nii')\n",
    "bg_img = nib.load('/usr/local/fsl/data/standard/MNI152_T1_1mm_brain.nii.gz')\n",
    "\n",
    "#cmap = ListedColormap(['#0200F5', '#EA33F7', '#EA3324', '#EA3324', '#EA3324', '#EA33F7', '#0200F5'])\n",
    "cmap = ListedColormap(['#0200F5', '#EA33F7', '#EA3324'])\n",
    "cmap2 = ListedColormap(['#EA3324', '#EA33F7', '#0200F5', '#0200F5', '#0200F5', '#EA33F7', '#EA3324'])\n",
    "\n",
    "def olp_and_conj(task, img1, img2, thresh=0.5):\n",
    "    img1_img = os.path.abspath(f'../../output/{task}/evaluation/output_clusterize/{img1}.nii.gz')\n",
    "    img2_img = os.path.abspath(f'../../output/{task}/evaluation/output_clusterize/{img2}.nii.gz')\n",
    "    img1_ = math_img(f'(img > {thresh}).astype(bool)', img=img1_img)\n",
    "    img2_ = math_img(f'(img > {thresh}).astype(bool)', img=img2_img)\n",
    "    conj_ = math_img('(img1 + img2) > 1.', img1=img1_, img2=img2_)\n",
    "    olp_conj_img = math_img('(img1-img3)*1. + (img2-img3)*3. + img3*2.', img1=img1_, img2=img2_, img3=conj_)\n",
    "    #olp_conj_img = math_img('(img1-img3).astype(bool)*-1. + (img2-img3).astype(bool)*1. + img3.astype(bool)*.1', img1=img1_, img2=img2_, img3=conj_)\n",
    "    return olp_conj_img\n",
    "\n",
    "def overlap(task, img1, img2, thresh=0.5):\n",
    "    img1_img = os.path.abspath(f'../../output/{task}/evaluation/output_clusterize/{img1}.nii.gz')\n",
    "    img2_img = os.path.abspath(f'../../output/{task}/evaluation/output_clusterize/{img2}.nii.gz')\n",
    "    img1_ = math_img(f'(img > {thresh}).astype(bool)', img=img1_img)\n",
    "    img2_ = math_img(f'(img > {thresh}).astype(bool)', img=img2_img)\n",
    "    overlap_img = math_img(f'(img1 + img2) > 1.', img1=img1_, img2=img2_)\n",
    "    return overlap_img\n",
    "\n",
    "def conjunction(task, img1, img2, thresh=0.5):\n",
    "    img1_img = os.path.abspath(f'../../output/{task}/evaluation/output_clusterize/{img1}.nii.gz')\n",
    "    img2_img = os.path.abspath(f'../../output/{task}/evaluation/output_clusterize/{img2}.nii.gz')\n",
    "    conj_img = math_img(f'(img1 > {thresh}).astype(bool) + (img2 > {thresh}).astype(bool)', img1=img1_img, img2=img2_img)\n",
    "    return conj_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0471cf4-98a0-4ec6-8946-7b69a1d3de16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# main effects - like in manuscript\n",
    "tasks = ['n-back', 'n-back', 'stroop', 'emo-faces']\n",
    "img1s = ['2BKvsBASE--0BKvsBASE_P95', '2BKvs0BK--1BKvs0BK_P95', 'IvsNRB--CvsNRB_P95', 'EMOvsBASE--NEUvsBASE_P95']\n",
    "img2s = ['2BKvs0BK_cFWE05', '2BKvs1BK_cFWE05', 'IvsC_cFWE05', 'EMOvsNEU_cFWE05']\n",
    "\n",
    "z_cut_coords = [[-32,-4,16,28,46,56], [-30,-24,2,12,26,46,56], [-28,-6,3,20,35,45,54], [-30,-20,-12,-2,4,30,48]]\n",
    "\n",
    "#colours = ['blue', 'magenta', 'red'] # '#0200F5', '#EA33F7', '#EA3324'\n",
    "colours = ['#35B779', '#FDE725', '#482878']\n",
    "\n",
    "fig_folder = '_figures'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792eb708-340f-4344-8148-2bffde7bfd10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# supplement - matched contrasts\n",
    "tasks = ['n-back', 'n-back', 'stroop', 'emo-faces']\n",
    "img1s = ['2BKvsBASE_matched_2vs0--0BKvsBASE_matched_2vs0_P95', '2BKvs0BK_matched_2vs1--1BKvs0BK_matched_2vs1_P95',\n",
    "         'IvsNRB_matched--CvsNRB_matched_P95', 'EMOvsBASE_matched--NEUvsBASE_matched_P95']\n",
    "img2s = ['2BKvs0BK_matched_2vs0_cFWE05', '2BKvs1BK_matched_2vs1_cFWE05', 'IvsC_matched_cFWE05', 'EMOvsNEU_matched_cFWE05']\n",
    "\n",
    "z_cut_coords = [[-32,-4,12,28,46,56], [-32,-24,2,12,26,46,56], [-28,-6,3,20,35,45,54], [-30,-20,-2,4,30,48]]\n",
    "\n",
    "colours = ['blue', 'magenta', 'red'] # '#0200F5', '#EA33F7', '#EA3324'\n",
    "colours = ['#35B779', '#FDE725', '#482878']\n",
    "\n",
    "fig_folder = '_supplement_figures'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb25f9e-2845-4c02-af2b-061e6d2d057f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = ['n-back', 'n-back', 'stroop', 'emo-faces']\n",
    "img1s = ['2BKvsBASE_cFWE05', '2BKvs0BK_cFWE05', 'IvsNRB_cFWE05', 'EMOvsBASE_cFWE05']\n",
    "img2s = ['0BKvsBASE_cFWE05', '1BKvs0BK_cFWE05', 'CvsNRB_cFWE05', 'NEUvsBASE_cFWE05']\n",
    "\n",
    "z_cut_coords = [[-32,-4,12,28,46,56], [-32,-24,2,12,26,46,56], [-28,-6,3,20,35,45,54], [-30,-20,-12,-2,4,30,48]]\n",
    "\n",
    "colours = ['#482878', '#35B779', '#FDE725'] # '#91bfdb', '#ffffbf', '#fc8d59'\n",
    "fig_folder = '_supplement_figures'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab168a64-f129-4df6-a1d6-2aa138ef2fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "surfaces = fetch_fslr()\n",
    "lh, rh = surfaces['inflated']\n",
    "\n",
    "cmap = ListedColormap(colours)\n",
    "cmap2 = ListedColormap(['#FFFFFF','#FFFFFF','#FFFFFF','#FFFFFF'] + colours)\n",
    "\n",
    "for task, img1, img2, cut_coords in zip(tasks, img1s, img2s, z_cut_coords):\n",
    "    plt.rcParams.update(plt.rcParamsDefault)\n",
    "\n",
    "    # create output dir\n",
    "    output_dir = os.path.abspath(f'../../output/{fig_folder}/{task}/comp_{img1}_{img2}')\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    \n",
    "    # Z slices plot\n",
    "    olp_conj_img = olp_and_conj(task, img1, img2)\n",
    "    disp = plotting.plot_stat_map(\n",
    "        olp_conj_img, display_mode='z',\n",
    "        #title=f'{img1} vs. {img2}',\n",
    "        draw_cross=False,\n",
    "        cmap=cmap2,\n",
    "        vmax=3,\n",
    "        cut_coords=cut_coords,\n",
    "        bg_img=bg_img,\n",
    "        black_bg=False\n",
    "    )\n",
    "    disp.savefig(os.path.join(output_dir, 'z_slices.png'), dpi=200)\n",
    "    plt.close()\n",
    "\n",
    "    # Surface plot\n",
    "    p1 = Plot(surf_lh=lh, surf_rh=rh, size=(1600, 400), zoom=1.2, layout='row', mirror_views=True, brightness=.6)\n",
    "    p2 = Plot(surf_lh=lh, surf_rh=rh, brightness=.6)\n",
    "\n",
    "    for p, name in zip([p1, p2], ['_row', '']):\n",
    "        olp = overlap(task, img1, img2)\n",
    "        img1_img = os.path.abspath(f'../../output/{task}/evaluation/output_clusterize/{img1}.nii.gz')\n",
    "        img2_img = os.path.abspath(f'../../output/{task}/evaluation/output_clusterize/{img2}.nii.gz')\n",
    "        img1_img = math_img('img > 0.5', img=img1_img)\n",
    "        img2_img = math_img('img > 0.5', img=img2_img)\n",
    "\n",
    "        gii_lh, gii_rh = mni152_to_fslr(olp, '32k')\n",
    "        img_lh = threshold(gii_lh.agg_data(), .1)\n",
    "        img_rh = threshold(gii_rh.agg_data(), .1)\n",
    "\n",
    "        gii2_lh, gii2_rh = mni152_to_fslr(img2_img, '32k')\n",
    "        img2_lh = threshold(gii2_lh.agg_data(), .1)\n",
    "        img2_rh = threshold(gii2_rh.agg_data(), .1)\n",
    "\n",
    "        gii1_lh, gii1_rh = mni152_to_fslr(img1_img, '32k')\n",
    "        img1_lh = threshold(gii1_lh.agg_data(), .1)\n",
    "        img1_rh = threshold(gii1_rh.agg_data(), .1)\n",
    "        \n",
    "        #p.add_layer({'left': lh, 'right': rh}, cmap='binary_r', cbar=False, alpha=.5)\n",
    "\n",
    "        p.add_layer(\n",
    "            {'left': img2_lh, 'right': img2_rh},\n",
    "            cmap=ListedColormap([colours[2]]), cbar=False)\n",
    "        p.add_layer(\n",
    "            {'left': img1_lh, 'right': img1_rh},\n",
    "            cmap=ListedColormap([colours[0]]), cbar=False)\n",
    "        p.add_layer(\n",
    "            {'left': img_lh, 'right': img_rh},\n",
    "            cmap=ListedColormap([colours[1]]), cbar=False)\n",
    "\n",
    "        fig = p.build()\n",
    "        fig.savefig(os.path.join(output_dir, f'surface_projection{name}.png'), dpi=200)\n",
    "        plt.close()\n",
    "     \n",
    "    # Venn diagram plots\n",
    "    # create venn output dir\n",
    "    voutput_dir = os.path.join(output_dir, 'venn')\n",
    "    if not os.path.exists(voutput_dir):\n",
    "        os.makedirs(voutput_dir)\n",
    "\n",
    "    vox_comp = calculate_voxel_similarity(img1=img1_img, img2=img2_img, gm_mask=gm_mask, thr_img1=.1, thr_img2=.1)\n",
    "    print(vox_comp)\n",
    "\n",
    "    subsets_vox = (vox_comp['voxel_map1']-vox_comp['voxel_overlap'],\n",
    "               vox_comp['voxel_map2']-vox_comp['voxel_overlap'],\n",
    "               vox_comp['voxel_overlap'])\n",
    "\n",
    "    plt.rcParams.update({'font.size': 24})\n",
    "    v = venn2(\n",
    "        subsets_vox,\n",
    "        set_labels = ('', ''),\n",
    "        #set_labels = ('CMeta-voxels', 'MCexp-voxels'),\n",
    "        #set_labels = (f'{img1}', f'{img2}'),\n",
    "        #subset_label_formatter = lambda v: '{:.2%}'.format(v/sum(subsets_vox)),\n",
    "        # percentage of total rounded to 1 decimal\n",
    "        subset_label_formatter=lambda x: str(x) + \"\\n(\" + f\"{(x/sum(subsets_vox)):1.0%}\" + \")\",\n",
    "        normalize_to = 1.0)\n",
    "    v.get_patch_by_id('10').set_color(colours[0])\n",
    "    v.get_patch_by_id('10').set_edgecolor('none')\n",
    "    v.get_patch_by_id('10').set_alpha(0.7)\n",
    "    #v.get_label_by_id('10').set_text(str(vox_comp['voxel_map1']-vox_comp['voxel_overlap']))\n",
    "    v.get_patch_by_id('01').set_color(colours[2])\n",
    "    v.get_patch_by_id('01').set_edgecolor('none')\n",
    "    v.get_patch_by_id('01').set_alpha(0.7)\n",
    "    #v.get_label_by_id('01').set_text(str(vox_comp['voxel_map2']-vox_comp['voxel_overlap']))\n",
    "    if subsets_vox[2] != 0:\n",
    "        v.get_patch_by_id('11').set_color(colours[1])\n",
    "        v.get_patch_by_id('11').set_alpha(0.7)\n",
    "        v.get_patch_by_id('11').set_edgecolor('none')\n",
    "        #v.get_label_by_id('11').set_text(str(vox_comp['voxel_overlap']))\n",
    "\n",
    "    plt.savefig(os.path.join(voutput_dir, 'voxel.svg'), dpi=200)\n",
    "    plt.close()\n",
    "\n",
    "    nib.save(olp_conj_img, os.path.join(output_dir, f'{img1}-1_AND-2_{img2}-3.nii.gz'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a9a145-1972-49b2-9cac-88fb55e82412",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.reporting import get_clusters_table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65152d07-2da9-4ab7-a699-0b2132984e60",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "similarity",
   "language": "python",
   "name": "similarity"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
